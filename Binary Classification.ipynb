{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80f10486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21aa7d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81472b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=load_breast_cancer(as_frame = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9860452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data':      mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       " 0          17.99         10.38          122.80     1001.0          0.11840   \n",
       " 1          20.57         17.77          132.90     1326.0          0.08474   \n",
       " 2          19.69         21.25          130.00     1203.0          0.10960   \n",
       " 3          11.42         20.38           77.58      386.1          0.14250   \n",
       " 4          20.29         14.34          135.10     1297.0          0.10030   \n",
       " ..           ...           ...             ...        ...              ...   \n",
       " 564        21.56         22.39          142.00     1479.0          0.11100   \n",
       " 565        20.13         28.25          131.20     1261.0          0.09780   \n",
       " 566        16.60         28.08          108.30      858.1          0.08455   \n",
       " 567        20.60         29.33          140.10     1265.0          0.11780   \n",
       " 568         7.76         24.54           47.92      181.0          0.05263   \n",
       " \n",
       "      mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       " 0             0.27760         0.30010              0.14710         0.2419   \n",
       " 1             0.07864         0.08690              0.07017         0.1812   \n",
       " 2             0.15990         0.19740              0.12790         0.2069   \n",
       " 3             0.28390         0.24140              0.10520         0.2597   \n",
       " 4             0.13280         0.19800              0.10430         0.1809   \n",
       " ..                ...             ...                  ...            ...   \n",
       " 564           0.11590         0.24390              0.13890         0.1726   \n",
       " 565           0.10340         0.14400              0.09791         0.1752   \n",
       " 566           0.10230         0.09251              0.05302         0.1590   \n",
       " 567           0.27700         0.35140              0.15200         0.2397   \n",
       " 568           0.04362         0.00000              0.00000         0.1587   \n",
       " \n",
       "      mean fractal dimension  ...  worst radius  worst texture  \\\n",
       " 0                   0.07871  ...        25.380          17.33   \n",
       " 1                   0.05667  ...        24.990          23.41   \n",
       " 2                   0.05999  ...        23.570          25.53   \n",
       " 3                   0.09744  ...        14.910          26.50   \n",
       " 4                   0.05883  ...        22.540          16.67   \n",
       " ..                      ...  ...           ...            ...   \n",
       " 564                 0.05623  ...        25.450          26.40   \n",
       " 565                 0.05533  ...        23.690          38.25   \n",
       " 566                 0.05648  ...        18.980          34.12   \n",
       " 567                 0.07016  ...        25.740          39.42   \n",
       " 568                 0.05884  ...         9.456          30.37   \n",
       " \n",
       "      worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       " 0             184.60      2019.0           0.16220            0.66560   \n",
       " 1             158.80      1956.0           0.12380            0.18660   \n",
       " 2             152.50      1709.0           0.14440            0.42450   \n",
       " 3              98.87       567.7           0.20980            0.86630   \n",
       " 4             152.20      1575.0           0.13740            0.20500   \n",
       " ..               ...         ...               ...                ...   \n",
       " 564           166.10      2027.0           0.14100            0.21130   \n",
       " 565           155.00      1731.0           0.11660            0.19220   \n",
       " 566           126.70      1124.0           0.11390            0.30940   \n",
       " 567           184.60      1821.0           0.16500            0.86810   \n",
       " 568            59.16       268.6           0.08996            0.06444   \n",
       " \n",
       "      worst concavity  worst concave points  worst symmetry  \\\n",
       " 0             0.7119                0.2654          0.4601   \n",
       " 1             0.2416                0.1860          0.2750   \n",
       " 2             0.4504                0.2430          0.3613   \n",
       " 3             0.6869                0.2575          0.6638   \n",
       " 4             0.4000                0.1625          0.2364   \n",
       " ..               ...                   ...             ...   \n",
       " 564           0.4107                0.2216          0.2060   \n",
       " 565           0.3215                0.1628          0.2572   \n",
       " 566           0.3403                0.1418          0.2218   \n",
       " 567           0.9387                0.2650          0.4087   \n",
       " 568           0.0000                0.0000          0.2871   \n",
       " \n",
       "      worst fractal dimension  \n",
       " 0                    0.11890  \n",
       " 1                    0.08902  \n",
       " 2                    0.08758  \n",
       " 3                    0.17300  \n",
       " 4                    0.07678  \n",
       " ..                       ...  \n",
       " 564                  0.07115  \n",
       " 565                  0.06637  \n",
       " 566                  0.07820  \n",
       " 567                  0.12400  \n",
       " 568                  0.07039  \n",
       " \n",
       " [569 rows x 30 columns],\n",
       " 'target': 0      0\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      0\n",
       "       ..\n",
       " 564    0\n",
       " 565    0\n",
       " 566    0\n",
       " 567    0\n",
       " 568    1\n",
       " Name: target, Length: 569, dtype: int64,\n",
       " 'frame':      mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       " 0          17.99         10.38          122.80     1001.0          0.11840   \n",
       " 1          20.57         17.77          132.90     1326.0          0.08474   \n",
       " 2          19.69         21.25          130.00     1203.0          0.10960   \n",
       " 3          11.42         20.38           77.58      386.1          0.14250   \n",
       " 4          20.29         14.34          135.10     1297.0          0.10030   \n",
       " ..           ...           ...             ...        ...              ...   \n",
       " 564        21.56         22.39          142.00     1479.0          0.11100   \n",
       " 565        20.13         28.25          131.20     1261.0          0.09780   \n",
       " 566        16.60         28.08          108.30      858.1          0.08455   \n",
       " 567        20.60         29.33          140.10     1265.0          0.11780   \n",
       " 568         7.76         24.54           47.92      181.0          0.05263   \n",
       " \n",
       "      mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       " 0             0.27760         0.30010              0.14710         0.2419   \n",
       " 1             0.07864         0.08690              0.07017         0.1812   \n",
       " 2             0.15990         0.19740              0.12790         0.2069   \n",
       " 3             0.28390         0.24140              0.10520         0.2597   \n",
       " 4             0.13280         0.19800              0.10430         0.1809   \n",
       " ..                ...             ...                  ...            ...   \n",
       " 564           0.11590         0.24390              0.13890         0.1726   \n",
       " 565           0.10340         0.14400              0.09791         0.1752   \n",
       " 566           0.10230         0.09251              0.05302         0.1590   \n",
       " 567           0.27700         0.35140              0.15200         0.2397   \n",
       " 568           0.04362         0.00000              0.00000         0.1587   \n",
       " \n",
       "      mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       " 0                   0.07871  ...          17.33           184.60      2019.0   \n",
       " 1                   0.05667  ...          23.41           158.80      1956.0   \n",
       " 2                   0.05999  ...          25.53           152.50      1709.0   \n",
       " 3                   0.09744  ...          26.50            98.87       567.7   \n",
       " 4                   0.05883  ...          16.67           152.20      1575.0   \n",
       " ..                      ...  ...            ...              ...         ...   \n",
       " 564                 0.05623  ...          26.40           166.10      2027.0   \n",
       " 565                 0.05533  ...          38.25           155.00      1731.0   \n",
       " 566                 0.05648  ...          34.12           126.70      1124.0   \n",
       " 567                 0.07016  ...          39.42           184.60      1821.0   \n",
       " 568                 0.05884  ...          30.37            59.16       268.6   \n",
       " \n",
       "      worst smoothness  worst compactness  worst concavity  \\\n",
       " 0             0.16220            0.66560           0.7119   \n",
       " 1             0.12380            0.18660           0.2416   \n",
       " 2             0.14440            0.42450           0.4504   \n",
       " 3             0.20980            0.86630           0.6869   \n",
       " 4             0.13740            0.20500           0.4000   \n",
       " ..                ...                ...              ...   \n",
       " 564           0.14100            0.21130           0.4107   \n",
       " 565           0.11660            0.19220           0.3215   \n",
       " 566           0.11390            0.30940           0.3403   \n",
       " 567           0.16500            0.86810           0.9387   \n",
       " 568           0.08996            0.06444           0.0000   \n",
       " \n",
       "      worst concave points  worst symmetry  worst fractal dimension  target  \n",
       " 0                  0.2654          0.4601                  0.11890       0  \n",
       " 1                  0.1860          0.2750                  0.08902       0  \n",
       " 2                  0.2430          0.3613                  0.08758       0  \n",
       " 3                  0.2575          0.6638                  0.17300       0  \n",
       " 4                  0.1625          0.2364                  0.07678       0  \n",
       " ..                    ...             ...                      ...     ...  \n",
       " 564                0.2216          0.2060                  0.07115       0  \n",
       " 565                0.1628          0.2572                  0.06637       0  \n",
       " 566                0.1418          0.2218                  0.07820       0  \n",
       " 567                0.2650          0.4087                  0.12400       0  \n",
       " 568                0.0000          0.2871                  0.07039       1  \n",
       " \n",
       " [569 rows x 31 columns],\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'breast_cancer.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e16e0c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['data'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9764682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['target'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32ca844d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca0c3e",
   "metadata": {},
   "source": [
    "#  Define explanatory and target variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dccba431",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset['data']\n",
    "y = dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97e610ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef1d4776",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.25, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf47eb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>11.850</td>\n",
       "      <td>17.46</td>\n",
       "      <td>75.54</td>\n",
       "      <td>432.7</td>\n",
       "      <td>0.08372</td>\n",
       "      <td>0.05642</td>\n",
       "      <td>0.026880</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.05715</td>\n",
       "      <td>...</td>\n",
       "      <td>13.060</td>\n",
       "      <td>25.75</td>\n",
       "      <td>84.35</td>\n",
       "      <td>517.8</td>\n",
       "      <td>0.13690</td>\n",
       "      <td>0.17580</td>\n",
       "      <td>0.13160</td>\n",
       "      <td>0.09140</td>\n",
       "      <td>0.3101</td>\n",
       "      <td>0.07007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>11.220</td>\n",
       "      <td>19.86</td>\n",
       "      <td>71.94</td>\n",
       "      <td>387.3</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.06779</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.007583</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.06028</td>\n",
       "      <td>...</td>\n",
       "      <td>11.980</td>\n",
       "      <td>25.78</td>\n",
       "      <td>76.91</td>\n",
       "      <td>436.1</td>\n",
       "      <td>0.14240</td>\n",
       "      <td>0.09669</td>\n",
       "      <td>0.01335</td>\n",
       "      <td>0.02022</td>\n",
       "      <td>0.3292</td>\n",
       "      <td>0.06522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.130</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.097910</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>13.590</td>\n",
       "      <td>17.84</td>\n",
       "      <td>86.24</td>\n",
       "      <td>572.3</td>\n",
       "      <td>0.07948</td>\n",
       "      <td>0.04052</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.012380</td>\n",
       "      <td>0.1573</td>\n",
       "      <td>0.05520</td>\n",
       "      <td>...</td>\n",
       "      <td>15.500</td>\n",
       "      <td>26.10</td>\n",
       "      <td>98.91</td>\n",
       "      <td>739.1</td>\n",
       "      <td>0.10500</td>\n",
       "      <td>0.07622</td>\n",
       "      <td>0.10600</td>\n",
       "      <td>0.05185</td>\n",
       "      <td>0.2335</td>\n",
       "      <td>0.06263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>16.690</td>\n",
       "      <td>20.20</td>\n",
       "      <td>107.10</td>\n",
       "      <td>857.6</td>\n",
       "      <td>0.07497</td>\n",
       "      <td>0.07112</td>\n",
       "      <td>0.036490</td>\n",
       "      <td>0.023070</td>\n",
       "      <td>0.1846</td>\n",
       "      <td>0.05325</td>\n",
       "      <td>...</td>\n",
       "      <td>19.180</td>\n",
       "      <td>26.56</td>\n",
       "      <td>127.30</td>\n",
       "      <td>1084.0</td>\n",
       "      <td>0.10090</td>\n",
       "      <td>0.29200</td>\n",
       "      <td>0.24770</td>\n",
       "      <td>0.08737</td>\n",
       "      <td>0.4677</td>\n",
       "      <td>0.07623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>18.810</td>\n",
       "      <td>19.98</td>\n",
       "      <td>120.90</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>0.08923</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.080200</td>\n",
       "      <td>0.058430</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.04996</td>\n",
       "      <td>...</td>\n",
       "      <td>19.960</td>\n",
       "      <td>24.30</td>\n",
       "      <td>129.00</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>0.12430</td>\n",
       "      <td>0.11600</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.12940</td>\n",
       "      <td>0.2567</td>\n",
       "      <td>0.05737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.460</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.227300</td>\n",
       "      <td>0.085430</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.08243</td>\n",
       "      <td>...</td>\n",
       "      <td>15.090</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.18530</td>\n",
       "      <td>1.05800</td>\n",
       "      <td>1.10500</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>9.436</td>\n",
       "      <td>18.32</td>\n",
       "      <td>59.82</td>\n",
       "      <td>278.6</td>\n",
       "      <td>0.10090</td>\n",
       "      <td>0.05956</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>0.014060</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>0.06959</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020</td>\n",
       "      <td>25.02</td>\n",
       "      <td>75.79</td>\n",
       "      <td>439.6</td>\n",
       "      <td>0.13330</td>\n",
       "      <td>0.10490</td>\n",
       "      <td>0.11440</td>\n",
       "      <td>0.05052</td>\n",
       "      <td>0.2454</td>\n",
       "      <td>0.08136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>9.720</td>\n",
       "      <td>18.22</td>\n",
       "      <td>60.73</td>\n",
       "      <td>288.1</td>\n",
       "      <td>0.06950</td>\n",
       "      <td>0.02344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1653</td>\n",
       "      <td>0.06447</td>\n",
       "      <td>...</td>\n",
       "      <td>9.968</td>\n",
       "      <td>20.83</td>\n",
       "      <td>62.25</td>\n",
       "      <td>303.8</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1909</td>\n",
       "      <td>0.06559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>11.510</td>\n",
       "      <td>23.93</td>\n",
       "      <td>74.52</td>\n",
       "      <td>403.5</td>\n",
       "      <td>0.09261</td>\n",
       "      <td>0.10210</td>\n",
       "      <td>0.111200</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.06570</td>\n",
       "      <td>...</td>\n",
       "      <td>12.480</td>\n",
       "      <td>37.16</td>\n",
       "      <td>82.28</td>\n",
       "      <td>474.2</td>\n",
       "      <td>0.12980</td>\n",
       "      <td>0.25170</td>\n",
       "      <td>0.36300</td>\n",
       "      <td>0.09653</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.08732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "293       11.850         17.46           75.54      432.7          0.08372   \n",
       "332       11.220         19.86           71.94      387.3          0.10540   \n",
       "565       20.130         28.25          131.20     1261.0          0.09780   \n",
       "278       13.590         17.84           86.24      572.3          0.07948   \n",
       "489       16.690         20.20          107.10      857.6          0.07497   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "277       18.810         19.98          120.90     1102.0          0.08923   \n",
       "9         12.460         24.04           83.97      475.9          0.11860   \n",
       "359        9.436         18.32           59.82      278.6          0.10090   \n",
       "192        9.720         18.22           60.73      288.1          0.06950   \n",
       "559       11.510         23.93           74.52      403.5          0.09261   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "293           0.05642        0.026880             0.022800         0.1875   \n",
       "332           0.06779        0.005006             0.007583         0.1940   \n",
       "565           0.10340        0.144000             0.097910         0.1752   \n",
       "278           0.04052        0.019970             0.012380         0.1573   \n",
       "489           0.07112        0.036490             0.023070         0.1846   \n",
       "..                ...             ...                  ...            ...   \n",
       "277           0.05884        0.080200             0.058430         0.1550   \n",
       "9             0.23960        0.227300             0.085430         0.2030   \n",
       "359           0.05956        0.027100             0.014060         0.1506   \n",
       "192           0.02344        0.000000             0.000000         0.1653   \n",
       "559           0.10210        0.111200             0.041050         0.1388   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "293                 0.05715  ...        13.060          25.75   \n",
       "332                 0.06028  ...        11.980          25.78   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "278                 0.05520  ...        15.500          26.10   \n",
       "489                 0.05325  ...        19.180          26.56   \n",
       "..                      ...  ...           ...            ...   \n",
       "277                 0.04996  ...        19.960          24.30   \n",
       "9                   0.08243  ...        15.090          40.68   \n",
       "359                 0.06959  ...        12.020          25.02   \n",
       "192                 0.06447  ...         9.968          20.83   \n",
       "559                 0.06570  ...        12.480          37.16   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "293            84.35       517.8           0.13690            0.17580   \n",
       "332            76.91       436.1           0.14240            0.09669   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "278            98.91       739.1           0.10500            0.07622   \n",
       "489           127.30      1084.0           0.10090            0.29200   \n",
       "..               ...         ...               ...                ...   \n",
       "277           129.00      1236.0           0.12430            0.11600   \n",
       "9              97.65       711.4           0.18530            1.05800   \n",
       "359            75.79       439.6           0.13330            0.10490   \n",
       "192            62.25       303.8           0.07117            0.02729   \n",
       "559            82.28       474.2           0.12980            0.25170   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "293          0.13160               0.09140          0.3101   \n",
       "332          0.01335               0.02022          0.3292   \n",
       "565          0.32150               0.16280          0.2572   \n",
       "278          0.10600               0.05185          0.2335   \n",
       "489          0.24770               0.08737          0.4677   \n",
       "..               ...                   ...             ...   \n",
       "277          0.22100               0.12940          0.2567   \n",
       "9            1.10500               0.22100          0.4366   \n",
       "359          0.11440               0.05052          0.2454   \n",
       "192          0.00000               0.00000          0.1909   \n",
       "559          0.36300               0.09653          0.2112   \n",
       "\n",
       "     worst fractal dimension  \n",
       "293                  0.07007  \n",
       "332                  0.06522  \n",
       "565                  0.06637  \n",
       "278                  0.06263  \n",
       "489                  0.07623  \n",
       "..                       ...  \n",
       "277                  0.05737  \n",
       "9                    0.20750  \n",
       "359                  0.08136  \n",
       "192                  0.06559  \n",
       "559                  0.08732  \n",
       "\n",
       "[426 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20891444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>13.40</td>\n",
       "      <td>20.52</td>\n",
       "      <td>88.64</td>\n",
       "      <td>556.7</td>\n",
       "      <td>0.11060</td>\n",
       "      <td>0.14690</td>\n",
       "      <td>0.14450</td>\n",
       "      <td>0.08172</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>0.07325</td>\n",
       "      <td>...</td>\n",
       "      <td>16.41</td>\n",
       "      <td>29.66</td>\n",
       "      <td>113.30</td>\n",
       "      <td>844.4</td>\n",
       "      <td>0.15740</td>\n",
       "      <td>0.38560</td>\n",
       "      <td>0.51060</td>\n",
       "      <td>0.20510</td>\n",
       "      <td>0.3585</td>\n",
       "      <td>0.11090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>13.21</td>\n",
       "      <td>25.25</td>\n",
       "      <td>84.10</td>\n",
       "      <td>537.9</td>\n",
       "      <td>0.08791</td>\n",
       "      <td>0.05205</td>\n",
       "      <td>0.02772</td>\n",
       "      <td>0.02068</td>\n",
       "      <td>0.1619</td>\n",
       "      <td>0.05584</td>\n",
       "      <td>...</td>\n",
       "      <td>14.35</td>\n",
       "      <td>34.23</td>\n",
       "      <td>91.29</td>\n",
       "      <td>632.9</td>\n",
       "      <td>0.12890</td>\n",
       "      <td>0.10630</td>\n",
       "      <td>0.13900</td>\n",
       "      <td>0.06005</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.06788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>14.02</td>\n",
       "      <td>15.66</td>\n",
       "      <td>89.59</td>\n",
       "      <td>606.5</td>\n",
       "      <td>0.07966</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>0.02087</td>\n",
       "      <td>0.02652</td>\n",
       "      <td>0.1589</td>\n",
       "      <td>0.05586</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>19.31</td>\n",
       "      <td>96.53</td>\n",
       "      <td>688.9</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.10170</td>\n",
       "      <td>0.06260</td>\n",
       "      <td>0.08216</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.06710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>14.26</td>\n",
       "      <td>18.17</td>\n",
       "      <td>91.22</td>\n",
       "      <td>633.1</td>\n",
       "      <td>0.06576</td>\n",
       "      <td>0.05220</td>\n",
       "      <td>0.02475</td>\n",
       "      <td>0.01374</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>0.05586</td>\n",
       "      <td>...</td>\n",
       "      <td>16.22</td>\n",
       "      <td>25.26</td>\n",
       "      <td>105.80</td>\n",
       "      <td>819.7</td>\n",
       "      <td>0.09445</td>\n",
       "      <td>0.21670</td>\n",
       "      <td>0.15650</td>\n",
       "      <td>0.07530</td>\n",
       "      <td>0.2636</td>\n",
       "      <td>0.07676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>13.03</td>\n",
       "      <td>18.42</td>\n",
       "      <td>82.61</td>\n",
       "      <td>523.8</td>\n",
       "      <td>0.08983</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.02562</td>\n",
       "      <td>0.02923</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.05863</td>\n",
       "      <td>...</td>\n",
       "      <td>13.30</td>\n",
       "      <td>22.81</td>\n",
       "      <td>84.46</td>\n",
       "      <td>545.9</td>\n",
       "      <td>0.09701</td>\n",
       "      <td>0.04619</td>\n",
       "      <td>0.04833</td>\n",
       "      <td>0.05013</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.06169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>23.21</td>\n",
       "      <td>26.97</td>\n",
       "      <td>153.50</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>0.09509</td>\n",
       "      <td>0.16820</td>\n",
       "      <td>0.19500</td>\n",
       "      <td>0.12370</td>\n",
       "      <td>0.1909</td>\n",
       "      <td>0.06309</td>\n",
       "      <td>...</td>\n",
       "      <td>31.01</td>\n",
       "      <td>34.51</td>\n",
       "      <td>206.00</td>\n",
       "      <td>2944.0</td>\n",
       "      <td>0.14810</td>\n",
       "      <td>0.41260</td>\n",
       "      <td>0.58200</td>\n",
       "      <td>0.25930</td>\n",
       "      <td>0.3103</td>\n",
       "      <td>0.08677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>10.51</td>\n",
       "      <td>20.19</td>\n",
       "      <td>68.64</td>\n",
       "      <td>334.2</td>\n",
       "      <td>0.11220</td>\n",
       "      <td>0.13030</td>\n",
       "      <td>0.06476</td>\n",
       "      <td>0.03068</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.07782</td>\n",
       "      <td>...</td>\n",
       "      <td>11.16</td>\n",
       "      <td>22.75</td>\n",
       "      <td>72.62</td>\n",
       "      <td>374.4</td>\n",
       "      <td>0.13000</td>\n",
       "      <td>0.20490</td>\n",
       "      <td>0.12950</td>\n",
       "      <td>0.06136</td>\n",
       "      <td>0.2383</td>\n",
       "      <td>0.09026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>12.34</td>\n",
       "      <td>12.27</td>\n",
       "      <td>78.94</td>\n",
       "      <td>468.5</td>\n",
       "      <td>0.09003</td>\n",
       "      <td>0.06307</td>\n",
       "      <td>0.02958</td>\n",
       "      <td>0.02647</td>\n",
       "      <td>0.1689</td>\n",
       "      <td>0.05808</td>\n",
       "      <td>...</td>\n",
       "      <td>13.61</td>\n",
       "      <td>19.27</td>\n",
       "      <td>87.22</td>\n",
       "      <td>564.9</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.20740</td>\n",
       "      <td>0.17910</td>\n",
       "      <td>0.10700</td>\n",
       "      <td>0.3110</td>\n",
       "      <td>0.07592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>13.53</td>\n",
       "      <td>10.94</td>\n",
       "      <td>87.91</td>\n",
       "      <td>559.2</td>\n",
       "      <td>0.12910</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.06877</td>\n",
       "      <td>0.06556</td>\n",
       "      <td>0.2403</td>\n",
       "      <td>0.06641</td>\n",
       "      <td>...</td>\n",
       "      <td>14.08</td>\n",
       "      <td>12.49</td>\n",
       "      <td>91.36</td>\n",
       "      <td>605.5</td>\n",
       "      <td>0.14510</td>\n",
       "      <td>0.13790</td>\n",
       "      <td>0.08539</td>\n",
       "      <td>0.07407</td>\n",
       "      <td>0.2710</td>\n",
       "      <td>0.07191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>19.59</td>\n",
       "      <td>18.15</td>\n",
       "      <td>130.70</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>0.11200</td>\n",
       "      <td>0.16660</td>\n",
       "      <td>0.25080</td>\n",
       "      <td>0.12860</td>\n",
       "      <td>0.2027</td>\n",
       "      <td>0.06082</td>\n",
       "      <td>...</td>\n",
       "      <td>26.73</td>\n",
       "      <td>26.39</td>\n",
       "      <td>174.90</td>\n",
       "      <td>2232.0</td>\n",
       "      <td>0.14380</td>\n",
       "      <td>0.38460</td>\n",
       "      <td>0.68100</td>\n",
       "      <td>0.22470</td>\n",
       "      <td>0.3643</td>\n",
       "      <td>0.09223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "512        13.40         20.52           88.64      556.7          0.11060   \n",
       "457        13.21         25.25           84.10      537.9          0.08791   \n",
       "439        14.02         15.66           89.59      606.5          0.07966   \n",
       "298        14.26         18.17           91.22      633.1          0.06576   \n",
       "37         13.03         18.42           82.61      523.8          0.08983   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "236        23.21         26.97          153.50     1670.0          0.09509   \n",
       "113        10.51         20.19           68.64      334.2          0.11220   \n",
       "527        12.34         12.27           78.94      468.5          0.09003   \n",
       "76         13.53         10.94           87.91      559.2          0.12910   \n",
       "162        19.59         18.15          130.70     1214.0          0.11200   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "512           0.14690         0.14450              0.08172         0.2116   \n",
       "457           0.05205         0.02772              0.02068         0.1619   \n",
       "439           0.05581         0.02087              0.02652         0.1589   \n",
       "298           0.05220         0.02475              0.01374         0.1635   \n",
       "37            0.03766         0.02562              0.02923         0.1467   \n",
       "..                ...             ...                  ...            ...   \n",
       "236           0.16820         0.19500              0.12370         0.1909   \n",
       "113           0.13030         0.06476              0.03068         0.1922   \n",
       "527           0.06307         0.02958              0.02647         0.1689   \n",
       "76            0.10470         0.06877              0.06556         0.2403   \n",
       "162           0.16660         0.25080              0.12860         0.2027   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "512                 0.07325  ...         16.41          29.66   \n",
       "457                 0.05584  ...         14.35          34.23   \n",
       "439                 0.05586  ...         14.91          19.31   \n",
       "298                 0.05586  ...         16.22          25.26   \n",
       "37                  0.05863  ...         13.30          22.81   \n",
       "..                      ...  ...           ...            ...   \n",
       "236                 0.06309  ...         31.01          34.51   \n",
       "113                 0.07782  ...         11.16          22.75   \n",
       "527                 0.05808  ...         13.61          19.27   \n",
       "76                  0.06641  ...         14.08          12.49   \n",
       "162                 0.06082  ...         26.73          26.39   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "512           113.30       844.4           0.15740            0.38560   \n",
       "457            91.29       632.9           0.12890            0.10630   \n",
       "439            96.53       688.9           0.10340            0.10170   \n",
       "298           105.80       819.7           0.09445            0.21670   \n",
       "37             84.46       545.9           0.09701            0.04619   \n",
       "..               ...         ...               ...                ...   \n",
       "236           206.00      2944.0           0.14810            0.41260   \n",
       "113            72.62       374.4           0.13000            0.20490   \n",
       "527            87.22       564.9           0.12920            0.20740   \n",
       "76             91.36       605.5           0.14510            0.13790   \n",
       "162           174.90      2232.0           0.14380            0.38460   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "512          0.51060               0.20510          0.3585   \n",
       "457          0.13900               0.06005          0.2444   \n",
       "439          0.06260               0.08216          0.2136   \n",
       "298          0.15650               0.07530          0.2636   \n",
       "37           0.04833               0.05013          0.1987   \n",
       "..               ...                   ...             ...   \n",
       "236          0.58200               0.25930          0.3103   \n",
       "113          0.12950               0.06136          0.2383   \n",
       "527          0.17910               0.10700          0.3110   \n",
       "76           0.08539               0.07407          0.2710   \n",
       "162          0.68100               0.22470          0.3643   \n",
       "\n",
       "     worst fractal dimension  \n",
       "512                  0.11090  \n",
       "457                  0.06788  \n",
       "439                  0.06710  \n",
       "298                  0.07676  \n",
       "37                   0.06169  \n",
       "..                       ...  \n",
       "236                  0.08677  \n",
       "113                  0.09026  \n",
       "527                  0.07592  \n",
       "76                   0.07191  \n",
       "162                  0.09223  \n",
       "\n",
       "[143 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2001df0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293    1\n",
       "332    1\n",
       "565    0\n",
       "278    1\n",
       "489    0\n",
       "      ..\n",
       "277    0\n",
       "9      0\n",
       "359    1\n",
       "192    1\n",
       "559    1\n",
       "Name: target, Length: 426, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10cd9ca",
   "metadata": {},
   "source": [
    "# scaling the x and y values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d01bebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a597a6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_train = StandardScaler()\n",
    "X_train = ss_train.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9904c78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_test = StandardScaler()\n",
    "X_test = ss_test.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "246de3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0345148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab3de05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "036abf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9850402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f24b3945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb1b9c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred=model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80c16764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e134f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51,  2],\n",
       "       [ 4, 86]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "confusion_matrix(y_test,Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3e6e317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive(TP)  =  86\n",
      "False Positive(FP) =  2\n",
      "True Negative(TN)  =  51\n",
      "False Negative(FN) =  4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, Pred)\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_test, Pred).ravel()\n",
    "\n",
    "print('True Positive(TP)  = ', TP)\n",
    "print('False Positive(FP) = ', FP)\n",
    "print('True Negative(TN)  = ', TN)\n",
    "print('False Negative(FN) = ', FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b2a2928",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(y_test,Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "571507fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958041958041958"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23740ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the binary classifier = 0.958\n"
     ]
    }
   ],
   "source": [
    "accuracy =  (TP + TN) / (TP + FP + TN + FN)\n",
    "\n",
    "print('Accuracy of the binary classifier = {:0.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f8364d",
   "metadata": {},
   "source": [
    "# Other binary classifiers in the scikit-learn library\n",
    "\n",
    "Logistic regression is just one of many classification algorithms defined in Scikit-learn. We'll compare several of the most common, but feel free to read more about these algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f00acb",
   "metadata": {},
   "source": [
    "# Initializing each binary classifier\n",
    "To quickly train each model in a loop, we'll initialize each model and store it by name in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "24367ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models['Logistic Regression'] = LogisticRegression()\n",
    "\n",
    "# Support Vector Machines\n",
    "from sklearn.svm import LinearSVC\n",
    "models['Support Vector Machines'] = LinearSVC()\n",
    "\n",
    "# Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "models['Decision Trees'] = DecisionTreeClassifier()\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "models['Random Forest'] = RandomForestClassifier()\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "models['Naive Bayes'] = GaussianNB()\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "models['K-Nearest Neighbor'] = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "438573f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "accuracy, precision, recall = {}, {}, {}\n",
    "\n",
    "for key in models.keys():\n",
    "    \n",
    "    # Fit the classifier\n",
    "    models[key].fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = models[key].predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy[key] = accuracy_score(predictions, y_test)\n",
    "    precision[key] = precision_score(predictions, y_test)\n",
    "    recall[key] = recall_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "46b90846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.977273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.965517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Trees</th>\n",
       "      <td>0.895105</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.988506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.945055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbor</th>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.936842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Accuracy  Precision    Recall\n",
       "Logistic Regression      0.958042   0.955556  0.977273\n",
       "Support Vector Machines  0.937063   0.933333  0.965517\n",
       "Decision Trees           0.895105   0.866667  0.962963\n",
       "Random Forest            0.965035   0.955556  0.988506\n",
       "Naive Bayes              0.937063   0.955556  0.945055\n",
       "K-Nearest Neighbor       0.951049   0.988889  0.936842"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_model = pd.DataFrame(index=models.keys(), columns=['Accuracy', 'Precision', 'Recall'])\n",
    "df_model['Accuracy'] = accuracy.values()\n",
    "df_model['Precision'] = precision.values()\n",
    "df_model['Recall'] = recall.values()\n",
    "\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ea4d635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df_model.plot.barh()\n",
    "ax.legend(ncol=len(models.keys()), bbox_to_anchor=(0, 1), loc='lower left', prop={'size': 14})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb4716",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f23f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
